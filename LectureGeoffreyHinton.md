# [Neural Networks for Machine Learning by Professor Geoffrey Hinton](https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
Coursera 2013, English, Advanced.
<hr/>

* [L1 : Introduction](https://www.youtube.com/watch?v=2fRnHVVLf1Y&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=6)
>* [Why do we need machine learning?](https://www.youtube.com/watch?v=4w0_mJ_6QoI&index=1&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [What are neural networks?](https://www.youtube.com/watch?v=0JrfYvn8zns&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=2)
>* [Some simple models of neurons](https://www.youtube.com/watch?v=z9lE4cowVFw&index=3&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [A simple example of learning](https://www.youtube.com/watch?v=iryPlswgRSA&index=4&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Three types of learning](https://www.youtube.com/watch?v=7IUhZ_XOYeU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=5)

* [L2 : The Perceptron learning procedure](https://www.youtube.com/watch?v=oID20dIrV94&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=12)
>* [An overview of the main types of neural network architecture](https://www.youtube.com/watch?v=KUV-r3yEri4&index=7&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Perceptrons: The first generation of neural networks](https://www.youtube.com/watch?v=TVJBOQzIKLY&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=8)
>* [A geometrical view of perceptrons](https://www.youtube.com/watch?v=X-H2T9uv8Kg&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=9)
>* [Why the learning works](https://www.youtube.com/watch?v=hsgyh4NaP7U&index=10&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [What perceptrons can't do](https://www.youtube.com/watch?v=BNcvqxohlXQ&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=11)

* [L3 : The backpropagation learning procedure](https://www.youtube.com/watch?v=a_v1DFjWYhY&index=18&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Learning the weights of a linear neuron](https://www.youtube.com/watch?v=-ducAlST5ag&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=13)
>* [The error surface for a linear neuron](https://www.youtube.com/watch?v=g2c0AlazcaU&index=14&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Learning the weights of a logistic output neuron](https://www.youtube.com/watch?v=dSmtyGrCdx4&index=15&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [The backpropagation algorithm](https://www.youtube.com/watch?v=XPFZwKSQkfM&index=16&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [How to use the derivatives computed by the backpropagation algorithm](https://www.youtube.com/watch?v=AMT9raJ2SUU&index=17&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

* [L4 : Learning feature vectors for words](https://www.youtube.com/watch?v=Rtk_juucCHc&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=24)
>* [Learning to predict the next word](https://www.youtube.com/watch?v=EHmvRc9_QR8&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=19)
>* [A brief diversion into cognitive science](https://www.youtube.com/watch?v=nudLcXmJ8_w&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=20)
>* [Another diversion : The softmax output function](https://www.youtube.com/watch?v=2-F1L-StqXU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=21)
>* [Neuro-probabilistic language models](https://www.youtube.com/watch?v=6IzhQvg0tNA&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=22)
>* [Ways to deal with the large number of possible outputs in neuro-probabilistic language models](https://www.youtube.com/watch?v=qzONfNBKUJM&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=23)

* [L5 : Object recognition with neural nets](https://www.youtube.com/watch?v=RTLI2K5OcWw&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=29)
>* [Why object recognition is difficult](https://www.youtube.com/watch?v=gsmUhuboJd0&index=25&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Ways to achieve viewpoint invariance](https://www.youtube.com/watch?v=6s5Yp7iVHgI&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=26)
>* [Convolutional neural networks for hand-written digit recognition](https://www.youtube.com/watch?v=gtYo1fB2lfE&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=27)
>* [Convolutional neural networks for object recognition](https://www.youtube.com/watch?v=95LF9E8qj-Q&index=28&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

* [L6 : Optimization: How to make the learning go faster](https://www.youtube.com/watch?v=bkjfbS_wnIk&index=35&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Overview of mini batch gradient descent](https://www.youtube.com/watch?v=tCTfb6PAr4w&index=30&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [A bag of tricks for mini batch gradient descent](https://www.youtube.com/watch?v=A4fEPcrrjU4&index=31&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [The momentum method](https://www.youtube.com/watch?v=N18Km9YIIug&index=32&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [ separate, adaptive learning rate for each connection](https://www.youtube.com/watch?v=76lj_cKBvmg&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=33)
>* [rmsprop: Divide the gradient by a running average of its recent magnitude](https://www.youtube.com/watch?v=SJ48OZ_qlrc&index=34&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

* [L7 : Recurrent neural networks](https://www.youtube.com/watch?v=9T2X6WRUwFU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=41)
>* [Modeling sequences: A brief overview](https://www.youtube.com/watch?v=eT1XsQbc_Sk&index=36&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Training RNNs with backpropagation](https://www.youtube.com/watch?v=iPiVj4fuJO0&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=37)
>* [A toy example of training an RNN](https://www.youtube.com/watch?v=NT5Sm7AJRwc&index=38&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Why it is difficult to train an RNN](https://www.youtube.com/watch?v=KJK2muqrlpQ&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=39)
>* [Long term short term memory](https://www.youtube.com/watch?v=uVzrIjkE-Mo&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=40)

* [L8 : More recurrent neural networks](https://www.youtube.com/watch?v=_gZ1NcYoVv4&index=46&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [A brief overview of "Hessian-Free" optimization](https://www.youtube.com/watch?v=Gqn_8GIG-iY&index=42&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Modeling character strings with multiplicative connections](https://www.youtube.com/watch?v=5zCdUg1w6oQ&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=43)
>* [Learning to predict the next character using HF](https://www.youtube.com/watch?v=tC6Yf9_Wry8&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=44)
>* [Echo state networks](https://www.youtube.com/watch?v=T12mA9h1VRs&index=45&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

Videos in L1~L8 that might worth watching are saved in my YouTube as "Watch Later"
From this point on (>=L9), all later videos might be worth watching!

* [L9 : Ways to make neural networks generalize better](https://www.youtube.com/watch?v=lbjlTd9wxWU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=53)
>* [Overview of ways to improve generalization](https://www.youtube.com/watch?v=kyuEpwOp1K0&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=47)
>* [Limiting the size of the weights](https://www.youtube.com/watch?v=Gi36wfl6BAw&index=48&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Using noise as a regularizer](https://www.youtube.com/watch?v=5Fveuxdg8rU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=49)
>* [Introduction to the Bayesian Approach](https://www.youtube.com/watch?v=NY1zXgIma3c&index=50&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>*  [The Bayesian interpretation of weight decay](https://www.youtube.com/watch?v=KCo8h3WAClc&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=51)
>* [MacKay's quick and dirty method of fixing weight costs](https://www.youtube.com/watch?v=_WZAD2uhvUM&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=52)

* [L10 : Combining multiple neural networks to improve generalization](https://www.youtube.com/watch?v=IVfAs03sBSU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=59)
>* [Why it helps to combine models](https://www.youtube.com/watch?v=JacgCGtxoj0&index=54&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Mixtures of Experts](https://www.youtube.com/watch?v=Uo3tC655I-w&index=55&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [The idea of full Bayesian learning](https://www.youtube.com/watch?v=Ra6RSZPWw9w&index=56&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Making full Bayesian learning practical](https://www.youtube.com/watch?v=0IXoayZ0egc&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=57)
>* [Dropout: an efficient way to combine neural nets](https://www.youtube.com/watch?v=kAwF--GJ-ek&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=58)

* [L11 : Hopfield nets and Boltzmann machines](https://www.youtube.com/watch?v=IP3W7cI01VY&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=11)
>* [Hopfield Nets](https://www.youtube.com/watch?v=cLuuAjvawhQ&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=61)
>* [Dealing with spurious minima in Hopfield Nets](https://www.youtube.com/watch?v=uurQcZhzblA&index=62&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Hopfield Nets with hidden units](https://www.youtube.com/watch?v=JayQy__1UGM&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=63)
>* [Using stochastic units to improve search](https://www.youtube.com/watch?v=6bTpq4OEYeI&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=64)
>* [How a Boltzmann Machine models data](https://www.youtube.com/watch?v=pci0drmGpGA&index=65&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

* [L12 : Restricted Boltzmann machines (RBMs)](https://www.youtube.com/watch?v=SY7ilsii2YM&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=12&t=1s)
>* [The Boltzmann Machine learning algorithm](https://www.youtube.com/watch?v=wpiSDA4XNaE&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=67&t=8s)
>* [More efficient ways to get the statistics](https://www.youtube.com/watch?v=pbq37Rgtpqw&index=68&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Restricted Boltzmann Machines](https://www.youtube.com/watch?v=UcAWwySuUZM&index=69&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [An example of Contrastive Divergence Learning](https://www.youtube.com/watch?v=JKw4z2tKl_4&index=70&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [RBMs for collaborative filtering](https://www.youtube.com/watch?v=UXQhVkDM05g&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=71)

* [L13 : Stacking RBMs to make Deep Belief Nets](https://www.youtube.com/watch?v=tM2QtkiXKxE&index=13&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [The ups and downs of backpropagation](https://www.youtube.com/watch?v=MpLds0oohC8&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=73)
>* [Belief Nets](https://www.youtube.com/watch?v=wrTdMkCu9Bk&index=74&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Learning Sigmoid Belief Nets](https://www.youtube.com/watch?v=uVJi1lDOEVw&index=75&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [The wake-sleep algorithm](https://www.youtube.com/watch?v=ZaJZlqP6TIs&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=76)

* [L14 : Deep neural nets with generative pre-training](https://www.youtube.com/watch?v=kkKu787Oph8&index=14&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Learning layers of features by stacking RBMs](https://www.youtube.com/watch?v=-TiIO_PX81Y&index=78&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Discriminative fine-tuning for DBNs](https://www.youtube.com/watch?v=HRXPYKU1xOs&index=79&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [What happens during discriminative fine-tuning?](https://www.youtube.com/watch?v=L779C8V_p4I&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=80)
>* [Modeling real-valued data with an RBM](https://www.youtube.com/watch?v=nsharLnuvjQ&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=81)
>* [RBMs are Infinite Sigmoid Belief Nets](https://www.youtube.com/watch?v=yYvN-BUpOB4&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=82)

* [L15 : Modeling hierarchical structure with neural nets](https://www.youtube.com/watch?v=D28cwQY9AXw&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=15)
>* [From Principal Components Analysis to Autoencoders](https://www.youtube.com/watch?v=XIu4-DSipu8&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=85)
>* [Deep Autoencoders](https://www.youtube.com/watch?v=ZRLTi7uP55Y&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=86)
>* [Deep autoencoders for document retrieval and visualization](https://www.youtube.com/watch?v=nycqIKx3Z-M&index=87&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Semantic hashing](https://www.youtube.com/watch?v=YblV9DCT1Ig&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=88)
>* [Learning binary codes for image retrieval](https://www.youtube.com/watch?v=-eWwSSRbLxM&index=89&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Shallow autoencoders for pre-training](https://www.youtube.com/watch?v=gt0ZBLjLEGA&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=90)

* [L16 : Recent applications of deep neural nets](https://www.youtube.com/watch?v=rsWoLB1GSoQ&index=16&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [ Learning a joint model of images and captions](https://www.youtube.com/watch?v=REfyrU4RjEI&index=91&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [Hierarchical coordinate frames](https://www.youtube.com/watch?v=am0__MkOxtk&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=92)
>* [Bayesian optimization of neural network hyperparameters](https://www.youtube.com/watch?v=ULuLoFIWQNc&index=93&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)
>* [The fog of progress](https://www.youtube.com/watch?v=mMfiY8bK7EU&list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0&index=94)
